---

author: federico bruzzone
title: introduction - machine learning pt.1 
date: 2023-06-06
draft: true 
tags: [computer-science, machine-learning, statistics, math, linear-algebra]
categories: [computer-science, machine-learning]

summary: "statistical methods for machine learning - questions & answers pt.2. Statistical learning"
katex: true
mathjax: true
math: true

;menu:
;  main:
;    parent: "design-patters"
;    weight: 1

---

## introduction

### write the formula for the square loss, the zero-one loss, and the logarithmic loss.

**absolute loss**: $\ell(y, \hat{y}) = |y-\hat{y}|$
    
**square loss**: $\ell(y, \hat{y}) = (y-\hat{y})^2$
    
**zero-one loss**: $\ell(y, \hat{y}) = \begin{cases} 
0 & \text{if } y = \hat{y}\\\ 
1 & \text{if } y \neq \hat{y}
\end{cases}$
    
**logarithmic loss**: $\ell(y, \hat{y}) = \begin{cases} 
\ln\frac{1}{\hat{y}} & \text{if } y = 1\\\ 
\ln\frac{1}{1-\hat{y}} & \text{if } y = 0 
\end{cases}$

---

### what does a learning algorithm receive in input? and what does it produce in output?

a **learning algorithm** training set as an input and output a predictor.

a **training set** is a set of example $\mathcal{s} = \{(\boldsymbol{x}_1, y_1), \dots, (\boldsymbol{x}_n, y_n)\}$ where $\boldsymbol{x}_i \in \mathcal{x}$ and $y_i \in \mathcal{y}$ for $i = 1, \dots, n$. training and test set are often prepared together, through a single round of data collection and annotation. 

a **predictor** is a function $f: \mathcal{x} \rightarrow \mathcal{y}$ mapping data points to labels.

---

### write the mathematical formula defining the training error of a predictor $h$.

$$\ell_{s}(f) = \frac{1}{n} \sum_{i=1}^n \ell(y\_i, h(\boldsymbol{x}_i))$$

---

### write the mathematical formula defining the erm algorithm over a class $\mathcal{h}$ of predictors. define the main quantities occurring in the formula.

let $\mathcal{f}$ be a given set of predictors and $\ell$ a loss function. the **erm** (empirical risk minimization) is a learning algorithm that outputs a predictor $\hat{f}$ that minimizes the training error.

$$\hat{f} \in \mathop{argmin}\_{f \in \mathcal{f}} \left( \ell_{s}(f) \right)$$

erm obviously fails when no predictor in $\mathcal{f}$  has a low test error.
this suggests the we should run erm with a large $\mathcal{f}$, so that there is a good chance that a predictor with low test error exists in $\mathcal{f}$.

in order not to fail erm, the training set should contain at least $\log_{2}|\mathcal{f}|$ distinct data points. equivalently, $|\mathcal{f}|$ should be smaller than $2^{m}$, where $m$ is the training set size.

---


### explain in words how overfitting and underfitting are defined in terms of behavior of an algorithm on training and test set. 

we may give specific names to the two ways of failing of erm (i.e., returning a predictor with high test error) for a generic learning algorithm $\mathcal{a}$: 


- if $\mathcal{a}$ fails by returning predictors with high training error, then we say that $\mathcal{a}$ is **underfitting**,
- if $\mathcal{a}$ fails by returning predictors with low training error, then we say that $\mathcal{a}$ is **overfitting**.

---

### name and describe three reasons why labels may be noisy. 

namely, when labels $y$ are not deterministically associated with data points $\boldsymbol{x}$. noise may occur for at least three (not mutually exclusive) reasons. 

1. **human in the loop**: the labels are assigned by a human annotator who decides the "true" label for each data point. in this case, different annotators may have different opinions.
2. **epistemic uncertainty**: each data point is represented by a feature vector $\boldsymbol{x}$ that does not contain enough information to uniquely determine the label.             
3. **aleatoric uncertainty**: the feature vector $\boldsymbol{x}$ representing a data point is obtained through noisy measurements. the label associated with a given $\boldsymbol{x}$ is then stochastic because the same $\boldsymbol{x}$ could have been generated by different data points.

noisy labels cause overfitting because they may mislead the algorithm with regard to what is the "true" label for a given data point.

## $k$-nn

### is $k$-nn more likely to overfit when $k$ is large or small?

the learning algorithm suffers from high test error for small values of $k$ (overfitting) and for large values of $k$ (underfitting).

## tree predictor

### write a short pseudo-code for building a tree classifier based on a training set.

we now describe a generic method to construct a binary tree given a training set $s$.
    
1. **initialization**: create $t$ with only the root $\ell$ and let $s_{\ell} = s$. let the label associated with the root be the most frequent label in $s_{\ell}$.
2. **main loop**: pick a leaf $\ell$ and replace it with an internal node $v$ creating two children $\ell^{'}$ and $\ell^{''}$. pick an attribute $i$ and a test $f : \mathcal{x}\_i \rightarrow \\{1,2\\}$. associate the test $f$ with $v$ and partition $s_{\ell}$ in the two subsets
        
$$s\_{\ell^{'}} = \\{(\boldsymbol{x}\_t, y\_t) \in s\_{\ell} : f(x\_{t,i}) = 1\\}\ \textmd{and}\ s\_{\ell^{''}} = \\{(\boldsymbol{x}\_t, y\_t)\in s\_{\ell} : f(x\_{t,i}) = 2\\}$$

let the labels associated with $s_{\ell^{'}}$ and$s_{\ell^{''}}$ be the most frequent labels in $s_{\ell^{'}}$ and $s_{\ell^{''}}$ respectively.

### what is the property of a splitting criterion $\psi$ ensuring that the training error of a tree classifier does not increase after a split? bonus points if you justify your answer with a proof.

to answer this question is sufficient to observe that $\psi$ (i.e, $\psi(x) = \min{\{x, 1 - x\}}$) is a concave function.\\
    we can then apply jensenâ€™s inequality, stating that $\psi(\alpha a + (1-\alpha)b) \geq \alpha\psi(a) + (1 - \alpha)\psi(b)$ for all $a,b \in \mathbb{r}$ and $\alpha \in [0,1]$.

hence, via jensen's inequality, we can study how the training error changes when $\ell$ is replaces by two new leaves $\ell^{'}$ and $\ell^{''}$.
    
$$
\psi \left( \frac{n_{\ell}^+}{n_{\ell}}\right){n_{\ell}} = \psi \left( \frac{n_{\ell^{'}}^+}{n_{\ell^{'}}}\frac{n_{\ell^{'}}}{n_{\ell}} + \frac{n_{\ell^{''}}^+}{n_{\ell^{''}}}\frac{n_{\ell^{''}}}{n_{\ell}}\right){n_{\ell}} \geq \psi\left( \frac{n_{\ell^{'}}^+}{n_{\ell^{'}}}\right)\frac{n_{\ell^{'}}^+}{n_{\ell}}n_{\ell} + \psi\left( \frac{n_{\ell^{''}}^+}{n_{\ell^{''}}}\right)\frac{n_{\ell^{''}}^+}{n_{\ell}}n_{\ell}
$$

meaning that a split never increaseses the training error.

### write the formula for at least two splitting criteria $\psi$ used in practice to build tree classifiers.

we use another type of splitting criterion $\psi$ because the one described in the previous question has strictly negative second derivative. define $p, r, q$ where $p$ is the parent node, $r$ and $q$ are the children nodes, and they are on the same side with respect to the $\alpha$ and $p = \alpha r + (1 - \alpha)q$.
in this case, $\psi(p) - \alpha\psi(r) + (1 - \alpha)\psi(q) = 0$ beacuse $\psi$ is a straight line.

some example of functions $\psi$ used in practice are 
1. **gini function**: $\psi(p) = 2p(1-p)$
2. **scaled entropy**: $\psi(p) = -\frac{p}{2}\log_2(p) - \frac{1-p}{2}\log_2(1-p)$
3. $\psi(p) = \sqrt{p(1-p)}$


